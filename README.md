# Transformers 

## Encoder:
Converts input sequence of tokens into a sequence of embeddings that is well suited for tasks like classification, NER etc.
BERT and its variants belong to this class of architecture.


Encoder contains the following sublayers:
- multihead self attention layer
- fully connected FF layer
